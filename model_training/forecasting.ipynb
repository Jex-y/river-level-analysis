{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: torch_xla-1.13-cp38-cp38m-linux_x86_64.whl is not a supported wheel on this platform.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q cloud-tpu-client https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.13-cp38-cp38m-linux_x86_64.whl\n",
    "%pip install -q hydrology polars neuralforecast wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydrology import HydrologyApi, Measure\n",
    "from datetime import datetime\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params = ({'observedProperty': ['waterLevel'], 'riverName': 'River Wear', 'status.label': 'Active'},)\n",
      "params = ({'observedProperty': ['rainfall'], 'lat': 54.774, 'long': -1.558, 'dist': 15, 'status.label': 'Active'},)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>Durham New Elvet Bridge level-i-900-m</th><th>North Dalton rainfall-t-900-mm</th><th>Sunderland Bridge level-i-900-m</th><th>Chester Le Street level-i-900-m</th><th>Knitlsey Mill rainfall-t-900-mm</th><th>Witton Park level-i-900-m</th><th>Peterlee rainfall-t-900-mm</th><th>Evenwood Gate rainfall-t-900-mm</th><th>Fulwell rainfall-t-900-mm</th><th>Stanhope level-i-900-m</th><th>Tunstall rainfall-t-900-mm</th><th>Harpington Hill Farm rainfall-t-900-mm</th></tr><tr><td>datetime[μs]</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>2021-01-06 02:45:00</td><td>0.752</td><td>0.0</td><td>0.703</td><td>0.857</td><td>0.0</td><td>0.635</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.391</td><td>0.0</td><td>0.0</td></tr><tr><td>2021-01-06 03:00:00</td><td>0.75</td><td>0.0</td><td>0.701</td><td>0.855</td><td>0.0</td><td>0.635</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.392</td><td>0.0</td><td>0.2</td></tr><tr><td>2021-01-06 03:15:00</td><td>0.745</td><td>0.0</td><td>0.699</td><td>0.854</td><td>0.0</td><td>0.634</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.391</td><td>0.0</td><td>0.2</td></tr><tr><td>2021-01-06 03:30:00</td><td>0.745</td><td>0.0</td><td>0.696</td><td>0.855</td><td>0.0</td><td>0.635</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.391</td><td>0.0</td><td>0.0</td></tr><tr><td>2021-01-06 03:45:00</td><td>0.743</td><td>0.0</td><td>0.695</td><td>0.855</td><td>0.0</td><td>0.634</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.391</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ timestamp ┆ Durham    ┆ North     ┆ Sunderlan ┆ … ┆ Fulwell   ┆ Stanhope  ┆ Tunstall  ┆ Harpingt │\n",
       "│ ---       ┆ New Elvet ┆ Dalton    ┆ d Bridge  ┆   ┆ rainfall- ┆ level-i-9 ┆ rainfall- ┆ on Hill  │\n",
       "│ datetime[ ┆ Bridge    ┆ rainfall- ┆ level-i-9 ┆   ┆ t-900-mm  ┆ 00-m      ┆ t-900-mm  ┆ Farm rai │\n",
       "│ μs]       ┆ level-…   ┆ t-900-mm  ┆ 00-…      ┆   ┆ ---       ┆ ---       ┆ ---       ┆ nfall-…  │\n",
       "│           ┆ ---       ┆ ---       ┆ ---       ┆   ┆ f32       ┆ f32       ┆ f32       ┆ ---      │\n",
       "│           ┆ f32       ┆ f32       ┆ f32       ┆   ┆           ┆           ┆           ┆ f32      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 2021-01-0 ┆ 0.752     ┆ 0.0       ┆ 0.703     ┆ … ┆ 0.0       ┆ 0.391     ┆ 0.0       ┆ 0.0      │\n",
       "│ 6         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 02:45:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2021-01-0 ┆ 0.75      ┆ 0.0       ┆ 0.701     ┆ … ┆ 0.0       ┆ 0.392     ┆ 0.0       ┆ 0.2      │\n",
       "│ 6         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 03:00:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2021-01-0 ┆ 0.745     ┆ 0.0       ┆ 0.699     ┆ … ┆ 0.0       ┆ 0.391     ┆ 0.0       ┆ 0.2      │\n",
       "│ 6         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 03:15:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2021-01-0 ┆ 0.745     ┆ 0.0       ┆ 0.696     ┆ … ┆ 0.0       ┆ 0.391     ┆ 0.0       ┆ 0.0      │\n",
       "│ 6         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 03:30:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2021-01-0 ┆ 0.743     ┆ 0.0       ┆ 0.695     ┆ … ┆ 0.0       ┆ 0.391     ┆ 0.0       ┆ 0.0      │\n",
       "│ 6         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 03:45:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = HydrologyApi()\n",
    "\n",
    "level_stations = api.get_stations(Measure.MeasureType.LEVEL, river=\"River Wear\")\n",
    "rainfall_stations = api.get_stations(\n",
    "    Measure.MeasureType.RAINFALL, \n",
    "    position=(54.774, -1.558), radius=15\n",
    ").filter(\n",
    "    ~pl.col(\"station_name\").is_in(\n",
    "        # Stations with lots of missing data\n",
    "        [\n",
    "            \"ESH Winning\",\n",
    "            \"Stanley Hustledown\",\n",
    "            \"Washington\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "measures = [\n",
    "    Measure(station_id, Measure.MeasureType.LEVEL)\n",
    "    for station_id in level_stations[\"station_id\"]\n",
    "] + [\n",
    "    Measure(station_id, Measure.MeasureType.RAINFALL)\n",
    "    for station_id in rainfall_stations[\"station_id\"]\n",
    "]\n",
    "\n",
    "stations = pl.concat(\n",
    "    [\n",
    "        level_stations,\n",
    "        rainfall_stations,\n",
    "    ],\n",
    ").unique()\n",
    "\n",
    "df = api.get_measures(measures, stations, start_date=datetime(2007, 1, 1))\n",
    "train_split = 0.8\n",
    "train_records = int(len(df) * train_split)\n",
    "\n",
    "train_df = df.slice(0, train_records)\n",
    "test_df = df.slice(train_records)\n",
    "\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>Durham New Elvet Bridge level-i-900-m</th><th>North Dalton rainfall-t-900-mm</th><th>Sunderland Bridge level-i-900-m</th><th>Chester Le Street level-i-900-m</th><th>Knitlsey Mill rainfall-t-900-mm</th><th>Witton Park level-i-900-m</th><th>Peterlee rainfall-t-900-mm</th><th>Evenwood Gate rainfall-t-900-mm</th><th>Fulwell rainfall-t-900-mm</th><th>Stanhope level-i-900-m</th><th>Tunstall rainfall-t-900-mm</th><th>Harpington Hill Farm rainfall-t-900-mm</th><th>cos_day_of_year</th><th>sin_day_of_year</th><th>years_since_2007</th></tr><tr><td>datetime[μs]</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2007-01-01 00:00:00</td><td>0.726</td><td>0.0</td><td>0.851</td><td>0.824</td><td>0.0</td><td>1.009</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.859</td><td>0.0</td><td>0.0</td><td>0.999852</td><td>0.017213</td><td>0.0</td></tr><tr><td>2007-01-01 00:15:00</td><td>0.73</td><td>0.0</td><td>0.863</td><td>0.821</td><td>0.0</td><td>0.997</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.855</td><td>0.0</td><td>0.0</td><td>0.999852</td><td>0.017213</td><td>0.000029</td></tr><tr><td>2007-01-01 00:30:00</td><td>0.74</td><td>0.0</td><td>0.876</td><td>0.823</td><td>0.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.845</td><td>0.0</td><td>0.0</td><td>0.999852</td><td>0.017213</td><td>0.000057</td></tr><tr><td>2007-01-01 00:45:00</td><td>0.744</td><td>0.0</td><td>0.886</td><td>0.819</td><td>0.0</td><td>1.001</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.826</td><td>0.0</td><td>0.0</td><td>0.999852</td><td>0.017213</td><td>0.000086</td></tr><tr><td>2007-01-01 01:00:00</td><td>0.763</td><td>0.0</td><td>0.894</td><td>0.823</td><td>0.0</td><td>0.993</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.825</td><td>0.0</td><td>0.0</td><td>0.999852</td><td>0.017213</td><td>0.000114</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ timestamp ┆ Durham    ┆ North     ┆ Sunderlan ┆ … ┆ Harpingto ┆ cos_day_o ┆ sin_day_o ┆ years_si │\n",
       "│ ---       ┆ New Elvet ┆ Dalton    ┆ d Bridge  ┆   ┆ n Hill    ┆ f_year    ┆ f_year    ┆ nce_2007 │\n",
       "│ datetime[ ┆ Bridge    ┆ rainfall- ┆ level-i-9 ┆   ┆ Farm rain ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ μs]       ┆ level-…   ┆ t-900-mm  ┆ 00-…      ┆   ┆ fall-…    ┆ f64       ┆ f64       ┆ f64      │\n",
       "│           ┆ ---       ┆ ---       ┆ ---       ┆   ┆ ---       ┆           ┆           ┆          │\n",
       "│           ┆ f32       ┆ f32       ┆ f32       ┆   ┆ f32       ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 2007-01-0 ┆ 0.726     ┆ 0.0       ┆ 0.851     ┆ … ┆ 0.0       ┆ 0.999852  ┆ 0.017213  ┆ 0.0      │\n",
       "│ 1         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 00:00:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2007-01-0 ┆ 0.73      ┆ 0.0       ┆ 0.863     ┆ … ┆ 0.0       ┆ 0.999852  ┆ 0.017213  ┆ 0.000029 │\n",
       "│ 1         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 00:15:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2007-01-0 ┆ 0.74      ┆ 0.0       ┆ 0.876     ┆ … ┆ 0.0       ┆ 0.999852  ┆ 0.017213  ┆ 0.000057 │\n",
       "│ 1         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 00:30:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2007-01-0 ┆ 0.744     ┆ 0.0       ┆ 0.886     ┆ … ┆ 0.0       ┆ 0.999852  ┆ 0.017213  ┆ 0.000086 │\n",
       "│ 1         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 00:45:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2007-01-0 ┆ 0.763     ┆ 0.0       ┆ 0.894     ┆ … ┆ 0.0       ┆ 0.999852  ┆ 0.017213  ┆ 0.000114 │\n",
       "│ 1         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 01:00:00  ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import pi\n",
    "\n",
    "start_year = 2007\n",
    "\n",
    "time_features = (\n",
    "    train_df\n",
    "    .select(pl.col(\"timestamp\"))\n",
    "    .with_columns(\n",
    "        (pl.col(\"timestamp\").dt.ordinal_day() / 365).alias(\"day_of_year\"),\n",
    "        ((pl.col(\"timestamp\").dt.epoch(time_unit='s') - datetime(start_year, 1, 1).timestamp()) / (60 * 60 * 24 * 365.2524)).alias(f\"years_since_{start_year}\"),\n",
    "    )\n",
    "    .select(\n",
    "      (pl.col(\"day_of_year\") * 2 * pi).cos().alias(\"cos_day_of_year\"),\n",
    "      (pl.col(\"day_of_year\") * 2 * pi).sin().alias(\"sin_day_of_year\"),\n",
    "       pl.col(f\"years_since_{start_year}\")\n",
    "    )\n",
    ")\n",
    "\n",
    "train_df = pl.concat([train_df, time_features], how='horizontal')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((491440, 14), (491440, 1))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X_preprocessing = make_column_transformer(\n",
    "      (\n",
    "          StandardScaler(),\n",
    "          make_column_selector(pattern='level-i-900-m'),\n",
    "      ),\n",
    "      (\n",
    "          MinMaxScaler(),\n",
    "          make_column_selector(pattern='rainfall-t-900-mm'),\n",
    "      ),\n",
    "      remainder='passthrough'\n",
    ")\n",
    "\n",
    "y_preprocessing = StandardScaler()\n",
    "\n",
    "X_train = train_df.select(pl.col(\"*\").exclude(\"timestamp\", \"Durham New Elvet Bridge level-i-900-m\")).to_pandas()\n",
    "y_train = train_df.select(\"Durham New Elvet Bridge level-i-900-m\").to_numpy()\n",
    "\n",
    "X_train = X_preprocessing.fit_transform(X_train)\n",
    "y_train = y_preprocessing.fit_transform(y_train)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        X_past: np.array,\n",
    "        y: np.array,\n",
    "        seq_length: int = 4 * 24,\n",
    "        pred_length: int = 4 * 6,\n",
    "    ):\n",
    "        self.X_past = X_past\n",
    "        self.y = y\n",
    "        self.seq_length = seq_length\n",
    "        self.pred_length = pred_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_past) - self.seq_length - self.pred_length + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.X_past[idx:idx+self.seq_length],\n",
    "            self.y[idx+self.seq_length:idx+self.seq_length+self.pred_length]\n",
    "        )\n",
    "        \n",
    "dataset = TimeSeriesDataset(X_train, y_train)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "class Transpose(nn.Module):\n",
    "    def __init__(self, *dims, contiguous=False):\n",
    "        super().__init__()\n",
    "        self.dims, self.contiguous = dims, contiguous\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.contiguous:\n",
    "            return x.transpose(*self.dims).contiguous()\n",
    "        else:\n",
    "            return x.transpose(*self.dims)\n",
    "\n",
    "\n",
    "def get_activation_fn(activation):\n",
    "    if callable(activation):\n",
    "        return activation()\n",
    "    elif activation.lower() == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation.lower() == 'gelu':\n",
    "        return nn.GELU()\n",
    "    raise ValueError(\n",
    "        f'{activation} is not available. You can use \"relu\", \"gelu\", or a callable'\n",
    "    )\n",
    "\n",
    "\n",
    "# decomposition\n",
    "\n",
    "\n",
    "class moving_avg(nn.Module):\n",
    "    \"\"\"\n",
    "    Moving average block to highlight the trend of time series\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        super(moving_avg, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # padding on the both ends of time series\n",
    "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
    "        x = torch.cat([front, x, end], dim=1)\n",
    "        x = self.avg(x.permute(0, 2, 1))\n",
    "        x = x.permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class series_decomp(nn.Module):\n",
    "    \"\"\"\n",
    "    Series decomposition block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size):\n",
    "        super(series_decomp, self).__init__()\n",
    "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        moving_mean = self.moving_avg(x)\n",
    "        res = x - moving_mean\n",
    "        return res, moving_mean\n",
    "\n",
    "\n",
    "# pos_encoding\n",
    "\n",
    "\n",
    "def PositionalEncoding(q_len, d_model, normalize=True):\n",
    "    pe = torch.zeros(q_len, d_model)\n",
    "    position = torch.arange(0, q_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    if normalize:\n",
    "        pe = pe - pe.mean()\n",
    "        pe = pe / (pe.std() * 10)\n",
    "    return pe\n",
    "\n",
    "\n",
    "SinCosPosEncoding = PositionalEncoding\n",
    "\n",
    "\n",
    "def Coord2dPosEncoding(\n",
    "    q_len, d_model, exponential=False, normalize=True, eps=1e-3, verbose=False\n",
    "):\n",
    "    x = 0.5 if exponential else 1\n",
    "    i = 0\n",
    "    for i in range(100):\n",
    "        cpe = (\n",
    "            2\n",
    "            * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x)\n",
    "            * (torch.linspace(0, 1, d_model).reshape(1, -1) ** x)\n",
    "            - 1\n",
    "        )\n",
    "        if abs(cpe.mean()) <= eps:\n",
    "            break\n",
    "        elif cpe.mean() > eps:\n",
    "            x += 0.001\n",
    "        else:\n",
    "            x -= 0.001\n",
    "        i += 1\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "\n",
    "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
    "    cpe = (\n",
    "        2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** (0.5 if exponential else 1))\n",
    "        - 1\n",
    "    )\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "\n",
    "def positional_encoding(pe, learn_pe, q_len, d_model):\n",
    "    # Positional encoding\n",
    "    if pe == None:\n",
    "        W_pos = torch.empty(\n",
    "            (q_len, d_model)\n",
    "        )  # pe = None and learn_pe = False can be used to measure impact of pe\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "        learn_pe = False\n",
    "    elif pe == 'zero':\n",
    "        W_pos = torch.empty((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'zeros':\n",
    "        W_pos = torch.empty((q_len, d_model))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'normal' or pe == 'gauss':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
    "    elif pe == 'uniform':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
    "    elif pe == 'lin1d':\n",
    "        W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
    "    elif pe == 'exp1d':\n",
    "        W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
    "    elif pe == 'lin2d':\n",
    "        W_pos = Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True)\n",
    "    elif pe == 'exp2d':\n",
    "        W_pos = Coord2dPosEncoding(q_len, d_model, exponential=True, normalize=True)\n",
    "    elif pe == 'sincos':\n",
    "        W_pos = PositionalEncoding(q_len, d_model, normalize=True)\n",
    "    else:\n",
    "        raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
    "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
    "    return nn.Parameter(W_pos, requires_grad=learn_pe)\n",
    "  \n",
    "class RevIN(nn.Module):\n",
    "  def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
    "      \"\"\"\n",
    "      :param num_features: the number of features or channels\n",
    "      :param eps: a value added for numerical stability\n",
    "      :param affine: if True, RevIN has learnable affine parameters\n",
    "      \"\"\"\n",
    "      super(RevIN, self).__init__()\n",
    "      self.num_features = num_features\n",
    "      self.eps = eps\n",
    "      self.affine = affine\n",
    "      self.subtract_last = subtract_last\n",
    "      if self.affine:\n",
    "          self._init_params()\n",
    "\n",
    "  def forward(self, x, mode: str):\n",
    "      if mode == 'norm':\n",
    "          self._get_statistics(x)\n",
    "          x = self._normalize(x)\n",
    "      elif mode == 'denorm':\n",
    "          x = self._denormalize(x)\n",
    "      else:\n",
    "          raise NotImplementedError\n",
    "      return x\n",
    "\n",
    "  def _init_params(self):\n",
    "      # initialize RevIN params: (C,)\n",
    "      self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "      self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "  def _get_statistics(self, x):\n",
    "      dim2reduce = tuple(range(1, x.ndim - 1))\n",
    "      if self.subtract_last:\n",
    "          self.last = x[:, -1, :].unsqueeze(1)\n",
    "      else:\n",
    "          self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "      self.stdev = torch.sqrt(\n",
    "          torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps\n",
    "      ).detach()\n",
    "\n",
    "  def _normalize(self, x):\n",
    "      if self.subtract_last:\n",
    "          x = x - self.last\n",
    "      else:\n",
    "          x = x - self.mean\n",
    "      x = x / self.stdev\n",
    "      if self.affine:\n",
    "          x = x * self.affine_weight\n",
    "          x = x + self.affine_bias\n",
    "      return x\n",
    "\n",
    "  def _denormalize(self, x):\n",
    "      if self.affine:\n",
    "          x = x - self.affine_bias\n",
    "          x = x / (self.affine_weight + self.eps * self.eps)\n",
    "      x = x * self.stdev\n",
    "      if self.subtract_last:\n",
    "          x = x + self.last\n",
    "      else:\n",
    "          x = x + self.mean\n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PatchMixerLayer(nn.Module):\n",
    "    def __init__(self, dim, a, kernel_size=8):\n",
    "        super().__init__()\n",
    "        self.Resnet = nn.Sequential(\n",
    "            nn.Conv1d(dim, dim, kernel_size=kernel_size, groups=dim, padding='same'),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(dim),\n",
    "        )\n",
    "        self.Conv_1x1 = nn.Sequential(\n",
    "            nn.Conv1d(dim, a, kernel_size=1), nn.GELU(), nn.BatchNorm1d(a)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.Resnet(x)  # x: [batch * n_val, patch_num, d_model]\n",
    "        x = self.Conv_1x1(x)  # x: [batch * n_val, a, d_model]\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, configs):\n",
    "        super().__init__()\n",
    "        self.model = Backbone(configs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        configs, \n",
    "        revin=True, \n",
    "        affine=True, \n",
    "        subtract_last=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nvals = configs.enc_in\n",
    "        self.lookback = configs.seq_len\n",
    "        self.forecasting = configs.pred_len\n",
    "        self.patch_size = configs.patch_len\n",
    "        self.stride = configs.stride\n",
    "        self.kernel_size = configs.mixer_kernel_size\n",
    "\n",
    "        self.PatchMixer_blocks = nn.ModuleList([])\n",
    "        self.padding_patch_layer = nn.ReplicationPad1d((0, self.stride))\n",
    "        self.patch_num = int((self.lookback - self.patch_size) / self.stride + 1) + 1\n",
    "        # if configs.a < 1 or configs.a > self.patch_num:\n",
    "        #     configs.a = self.patch_num\n",
    "        self.a = self.patch_num\n",
    "        self.d_model = configs.d_model\n",
    "        self.dropout = configs.dropout\n",
    "        self.head_dropout = configs.head_dropout\n",
    "        self.depth = configs.e_layers\n",
    "        for _ in range(self.depth):\n",
    "            self.PatchMixer_blocks.append(\n",
    "                PatchMixerLayer(\n",
    "                    dim=self.patch_num, a=self.a, kernel_size=self.kernel_size\n",
    "                )\n",
    "            )\n",
    "        self.W_P = nn.Linear(self.patch_size, self.d_model)\n",
    "        self.head0 = nn.Sequential(\n",
    "            nn.Flatten(start_dim=-2),\n",
    "            nn.Linear(self.patch_num * self.d_model, self.forecasting),\n",
    "            nn.Dropout(self.head_dropout),\n",
    "        )\n",
    "        self.head1 = nn.Sequential(\n",
    "            nn.Flatten(start_dim=-2),\n",
    "            nn.Linear(self.a * self.d_model, int(self.forecasting * 2)),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(self.head_dropout),\n",
    "            nn.Linear(int(self.forecasting * 2), self.forecasting),\n",
    "            nn.Dropout(self.head_dropout),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        # RevIn\n",
    "        self.revin = revin\n",
    "        if self.revin:\n",
    "            self.revin_layer = RevIN(\n",
    "                self.nvals, affine=affine, subtract_last=subtract_last\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.shape[0]\n",
    "        nvars = x.shape[-1]\n",
    "        if self.revin:\n",
    "            x = self.revin_layer(x, 'norm')\n",
    "        x = x.permute(0, 2, 1)  # x: [batch, n_val, seq_len]\n",
    "\n",
    "        x_lookback = self.padding_patch_layer(x)\n",
    "        x = x_lookback.unfold(\n",
    "            dimension=-1, size=self.patch_size, step=self.stride\n",
    "        )  # x: [batch, n_val, patch_num, patch_size]\n",
    "\n",
    "        x = self.W_P(x)  # x: [batch, n_val, patch_num, d_model]\n",
    "        x = torch.reshape(\n",
    "            x, (x.shape[0] * x.shape[1], x.shape[2], x.shape[3])\n",
    "        )  # x: [batch * n_val, patch_num, d_model]\n",
    "        x = self.dropout(x)\n",
    "        u = self.head0(x)\n",
    "\n",
    "        for PatchMixer_block in self.PatchMixer_blocks:\n",
    "            x = PatchMixer_block(x)\n",
    "        x = self.head1(x)\n",
    "        x = u + x\n",
    "        x = torch.reshape(x, (bs, nvars, -1))  # x: [batch, n_val, pred_len]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        if self.revin:\n",
    "            x = self.revin_layer(x, 'denorm')\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

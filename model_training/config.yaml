seed: null
prediction_length: 24
context_length: 96
train_epochs: 50
quantiles: [0.1, 0.5, 0.9]
train_split: 0.5

lr: 0.000005
batch_size: 4096
log_freq: 100

activation_function: relu
num_blocks: 2
dropout: 0.1
ff_dim: 32
normalize_before: true
norm_type: "layer"

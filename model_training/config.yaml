seed: null
prediction_length: 96
context_length: 192
train_epochs: 50
quantiles: [0.05, 0.5, 0.95]
train_split: 0.8
model_save_dir: './models'

lr: 0.00001
batch_size: 1024
log_freq: 100

activation_function: relu
num_blocks: 2
dropout: 0.1
ff_dim: 32
normalize_before: true
norm_type: "layer"

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, out_features)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 590201 entries, 2007-01-01 02:00:00 to 2023-11-01 00:00:00\n",
      "Columns: 164 entries, Level Chester Le Street to Rainfall Tunstall -7d\n",
      "dtypes: float16(164)\n",
      "memory usage: 189.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_feather('data/river_wear_lagged.feather')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['Level Durham New Elvet Bridge +15min',\n",
    "           'Level Durham New Elvet Bridge +30min',\n",
    "           'Level Durham New Elvet Bridge +60min',\n",
    "           'Level Durham New Elvet Bridge +90min',\n",
    "           'Level Durham New Elvet Bridge +120min']\n",
    "\n",
    "df['day_of_year'] = df.index.dayofyear\n",
    "df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "df = df.drop(columns=['day_of_year'])\n",
    "\n",
    "X = df.drop(targets, axis=1)\n",
    "y = df[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "\n",
    "# Normalize the data\n",
    "X_pipeline = ColumnTransformer(\n",
    "    [\n",
    "        ('Normalise level and flow', preprocessing.StandardScaler(), make_column_selector(pattern='Level|Flow')),\n",
    "        ('Normalise rainfall', preprocessing.MinMaxScaler(), make_column_selector(pattern='Rainfall')),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = X_pipeline.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pipeline = preprocessing.StandardScaler()\n",
    "\n",
    "y = y_pipeline.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle=True, test_size=0.2)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32), \n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    ), \n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_val, dtype=torch.float32), \n",
    "        torch.tensor(y_val, dtype=torch.float32)\n",
    "    ), \n",
    "    batch_size=256,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Model(X_train.shape[1], y_train.shape[1]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "metrics = {\n",
    "    'RMSE +15min': lambda y_pred, y_true: nn.functional.mse_loss(y_pred[:, 0], y_true[:, 0]),\n",
    "    'RMSE +30min': lambda y_pred, y_true: nn.functional.mse_loss(y_pred[:, 1], y_true[:, 1]),\n",
    "    'RMSE +60min': lambda y_pred, y_true: nn.functional.mse_loss(y_pred[:, 2], y_true[:, 2]),\n",
    "    'RMSE +90min': lambda y_pred, y_true: nn.functional.mse_loss(y_pred[:, 3], y_true[:, 3]),\n",
    "    'RMSE +120min': lambda y_pred, y_true: nn.functional.mse_loss(y_pred[:, 4], y_true[:, 4]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "def validate_model(model):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_metrics = {k: 0 for k in metrics}\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred = model(x)\n",
    "            val_loss += criterion(y_pred, y).item()\n",
    "            for k in metrics:\n",
    "                val_metrics[k] += metrics[k](y_pred, y).item()\n",
    "                \n",
    "        val_loss /= len(test_loader)\n",
    "        for k in metrics:\n",
    "            val_metrics[k] /= len(test_loader)\n",
    "            \n",
    "        wandb.log(\n",
    "            {\n",
    "                'val_loss': val_loss, \n",
    "                **{'val_' + k: v for k, v in val_metrics.items()}\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        return val_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:w8s6kc87) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da6876db8be43f0b66b5f4ff430dca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded\\r'), FloatProgress(value=0.09923719578641482, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>▁█▃▃▂▁▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_RMSE +120min</td><td>█▁▁▁▁</td></tr><tr><td>val_RMSE +15min</td><td>█▁▁▁▁</td></tr><tr><td>val_RMSE +30min</td><td>█▁▁▁▁</td></tr><tr><td>val_RMSE +60min</td><td>█▁▁▁▁</td></tr><tr><td>val_RMSE +90min</td><td>█▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.00301</td></tr><tr><td>val_RMSE +120min</td><td>0.00545</td></tr><tr><td>val_RMSE +15min</td><td>0.00229</td></tr><tr><td>val_RMSE +30min</td><td>0.00269</td></tr><tr><td>val_RMSE +60min</td><td>0.00404</td></tr><tr><td>val_RMSE +90min</td><td>0.00435</td></tr><tr><td>val_loss</td><td>0.00376</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-dragon-1</strong> at: <a href='https://wandb.ai/ejex/river-levels/runs/w8s6kc87' target=\"_blank\">https://wandb.ai/ejex/river-levels/runs/w8s6kc87</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231113_070727-w8s6kc87\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:w8s6kc87). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\code\\river-level-analysis\\wandb\\run-20231113_071055-0hsi2z3a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ejex/river-levels/runs/0hsi2z3a' target=\"_blank\">lively-butterfly-2</a></strong> to <a href='https://wandb.ai/ejex/river-levels' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ejex/river-levels' target=\"_blank\">https://wandb.ai/ejex/river-levels</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ejex/river-levels/runs/0hsi2z3a' target=\"_blank\">https://wandb.ai/ejex/river-levels/runs/0hsi2z3a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9153192b839a4c129d35a8f6acd054f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/100000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\river-level-analysis\\model.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/river-level-analysis/model.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_pred, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/river-level-analysis/model.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/river-level-analysis/model.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/river-level-analysis/model.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/river-level-analysis/model.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m train_losses[i \u001b[39m%\u001b[39m train_loss_smoothing] \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\river-level\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\river-level\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run = wandb.init(project='river-levels')\n",
    "\n",
    "train_iter = cycle(train_loader)\n",
    "\n",
    "train_steps = 100_000\n",
    "val_freq = 1000\n",
    "train_loss_smoothing = 100\n",
    "\n",
    "train_losses = torch.zeros(train_loss_smoothing)\n",
    "\n",
    "with tqdm(total=train_steps, desc=\"Train\", unit=\"batch\") as pbar:\n",
    "    for i in range(train_steps):\n",
    "        model.train()\n",
    "        x, y = next(train_iter)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses[i % train_loss_smoothing] = loss.item()\n",
    "        if i % train_loss_smoothing == 0:\n",
    "            wandb.log({'train_loss': train_losses.mean().item()})\n",
    "            pbar.postfix['train_loss'] = train_losses.mean().item()\n",
    "            pbar.update(train_loss_smoothing)\n",
    "        \n",
    "        if i % val_freq == 0:\n",
    "            val_loss = validate_model(model)\n",
    "            pbar.postfix['val_loss'] = val_loss\n",
    "            pbar.update(val_freq) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "with open('X_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(X_pipeline, f)\n",
    "with open('y_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump(y_pipeline, f)\n",
    "    \n",
    "run.log_artifact('model.pt')\n",
    "run.log_artifact('X_pipeline.pkl')\n",
    "run.log_artifact('y_pipeline.pkl')\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "river-level",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

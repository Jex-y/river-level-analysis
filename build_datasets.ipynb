{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode\n",
    "import urllib3\n",
    "import json\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from io import StringIO\n",
    "import os\n",
    "from enum import Enum\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measure(Enum):\n",
    "    LEVEL = 'level'\n",
    "    RAINFALL = 'rainfall'\n",
    "\n",
    "class HydrologyApi:\n",
    "    API_BASE_URL = \"https://environment.data.gov.uk/hydrology/\"\n",
    "    DATA_DIR = \"data\"\n",
    "    \n",
    "    def __init__(self, max_threads):\n",
    "        self.http = urllib3.PoolManager(maxsize=max_threads)\n",
    "        self.thread_pool = ThreadPoolExecutor(max_workers=max_threads)\n",
    "    \n",
    "    def get_stations_on_river(self, river):\n",
    "        api_url = self.API_BASE_URL + 'id/stations'\n",
    "        result = urlopen(\n",
    "            api_url + '?' + urlencode({'riverName': river})).read().decode('utf-8')\n",
    "        data = json.loads(result)\n",
    "        return pd.DataFrame(data['items'])\n",
    "    \n",
    "    def get_levels(self, station_id, start):\n",
    "        api_url = self.API_BASE_URL + f\"id/measures/{station_id}-level-i-900-m-qualified/readings\"\n",
    "        # result = urlopen(api_url).read().decode('utf-8')\n",
    "        result = self.http.request(\n",
    "            'GET',\n",
    "            api_url,\n",
    "            fields={\n",
    "                'mineq-date': start.strftime('%Y-%m-%d')             \n",
    "            }\n",
    "        ).data.decode('utf-8')\n",
    "        \n",
    "        data = json.loads(result)\n",
    "        return pd.DataFrame(data['items'])\n",
    "    \n",
    "    def _batch_request(self, api_url, query_params):\n",
    "        status = \"Pending\"\n",
    "\n",
    "        while status in (\"Pending\", \"InProgress\"):\n",
    "            print(f\"Making request to: {api_url}\")\n",
    "            \n",
    "            request = self.http.request(\n",
    "                'GET', \n",
    "                api_url, \n",
    "                headers={\n",
    "                    'Accept-Encoding': 'gzip'\n",
    "                }\n",
    "            )\n",
    "            content_type = request.headers['Content-Type']\n",
    "\n",
    "            if content_type == 'text/csv':\n",
    "                if len(request.data) == 0:\n",
    "                    print('Got empty CSV')\n",
    "                    return None\n",
    "                buffer = StringIO(request.data.decode('utf-8'))\n",
    "                return pd.read_csv(buffer, low_memory=False)\n",
    "            \n",
    "            assert content_type in (\n",
    "                'application/json',\n",
    "                'application/json;charset=UTF-8'), f\"Unexpected content type: {content_type}\"\n",
    "\n",
    "            data = json.loads(request.data.decode('utf-8'))\n",
    "            status = data[\"status\"]\n",
    "\n",
    "            if status == \"Pending\":\n",
    "                print(f\"Query is pending\")\n",
    "                pos_in_queue = data[\"positionInQueue\"]\n",
    "                print(f\"Position in queue: {pos_in_queue}\")\n",
    "                eta = data[\"eta\"] / 1000\n",
    "                print(f\"Estimated completion: {eta}\")\n",
    "                sleep(eta * 1.1)\n",
    "\n",
    "            elif status == \"InProgress\":\n",
    "                print(f\"Query in progress\")\n",
    "                eta = data[\"eta\"] / 1000\n",
    "                print(f\"Estimated completion: {eta}\")\n",
    "                sleep(eta * 1.1)\n",
    "\n",
    "            elif status in (\"Complete\", \"Completed\"):\n",
    "                print(f\"Query completed: {data}\")\n",
    "                csv_url = data[\"dataUrl\"] if \"dataUrl\" in data else data[\"url\"]\n",
    "                return pd.read_csv(csv_url, low_memory=False)\n",
    "\n",
    "            elif status == \"Failed\":\n",
    "                raise Exception(f\"Query failed, response: {data}\")\n",
    "\n",
    "            else:\n",
    "                raise Exception(f\"Unknown status: {data['status']}\")\n",
    "        \n",
    "    \n",
    "    def batch_get_levels(self, station_id, start_date=None):\n",
    "        api_url = self.API_BASE_URL + \\\n",
    "            f\"data/batch-readings/batch/?measure={station_id}-level-i-900-m-qualified\"\n",
    "            \n",
    "        return self._batch_request(api_url, {\n",
    "            'mineq-date': start_date\n",
    "        } if start_date else {})\n",
    "            \n",
    "    def batch_get_rainfall(self, station_id, start_date=None):\n",
    "        api_url = self.API_BASE_URL + \\\n",
    "            f\"data/batch-readings/batch/?measure={station_id}-rainfall-i-900\"\n",
    "            \n",
    "        return self._batch_request(api_url, {\n",
    "            'mineq-date': start_date\n",
    "        } if start_date else {})\n",
    "    \n",
    "    def batch_get_measure(self, measure: Measure, station_id, start_date=None):\n",
    "        return {\n",
    "            Measure.LEVEL: self.batch_get_levels,\n",
    "            Measure.RAINFALL: self.batch_get_rainfall\n",
    "        }[measure](station_id, start_date)\n",
    "        \n",
    "    def batch_get_measure_on_river(self, measure: Measure, river, start_date=None):\n",
    "        data = pd.DataFrame()\n",
    "    \n",
    "        stations = self.get_stations_on_river(river)\n",
    "        \n",
    "        threads = [\n",
    "            self.thread_pool.submit(\n",
    "                self.batch_get_measure, measure, station_id, start_date)\n",
    "            for station_id in stations['notation'].values\n",
    "        ]\n",
    "        \n",
    "        for thread, (station_id, station_name) in zip(threads, stations[['notation', 'label']].values):\n",
    "            new_data = thread.result()\n",
    "            if new_data is None:\n",
    "                print(f\"No new data for station: {station_name}\")\n",
    "                continue\n",
    "            new_data = new_data.drop(columns=['measure', 'date', 'qcode', 'completeness'])\n",
    "            new_data['station'] = station_name\n",
    "            new_data['station'] = new_data['station'].astype('category')\n",
    "            new_data['dateTime'] = pd.to_datetime(new_data['dateTime'])\n",
    "            new_data['value'] = new_data['value'].astype('float32')\n",
    "            new_data['quality'] = new_data['quality'].astype('category')\n",
    "            data = pd.concat([data, new_data])\n",
    "            data.drop_duplicates(subset=['dateTime', 'station'], inplace=True)\n",
    "        return data\n",
    "        \n",
    "    def get_filename(self, measure: Measure, river):\n",
    "        return f\"{river.lower().replace(' ', '_')}_{measure.value}_raw.parquet\"\n",
    "        \n",
    "    def update_dataframe(self, df: pd.DataFrame, measure: Measure, river: str):\n",
    "        # last_date = df['dateTime'].max()\n",
    "        # if last_date >= pd.to_datetime('today'):\n",
    "        #     print(f\"Data is up to date\")\n",
    "        #     return df\n",
    "        # df = pd.concat([df, self.batch_get_measure_on_river(measure, river, last_date.strftime('%Y-%m-%d'))])\n",
    "        # df.drop_duplicates(subset=['dateTime', 'station'], inplace=True)\n",
    "        # return df\n",
    "        assert measure == Measure.LEVEL\n",
    "        for station_name, station_id in self.get_stations_on_river(river)[['label', 'notation']].values:\n",
    "            print(f\"Updating data for station: {station_name}\")\n",
    "            last = df[df['station'] == station_name]['dateTime'].max()\n",
    "            new_measurements = self.get_levels(station_id, last)[['dateTime', 'value', 'quality']]\n",
    "            new_measurements['station'] = station_name\n",
    "            new_measurements['station'] = new_measurements['station'].astype('category')\n",
    "            new_measurements['dateTime'] = pd.to_datetime(new_measurements['dateTime'])\n",
    "            new_measurements['value'] = new_measurements['value'].astype('float32')\n",
    "            print(f\"Got {len(new_measurements)} new measurements\")\n",
    "            df = pd.concat([df, new_measurements])\n",
    "        df.drop_duplicates(subset=['dateTime', 'station'], inplace=True)\n",
    "        return df\n",
    "            \n",
    "    def load(self, measure: Measure, river):\n",
    "        filename = self.get_filename(measure, river)\n",
    "        filepath = os.path.join(self.DATA_DIR, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"Loading {filepath}\")\n",
    "            df = pd.read_parquet(filepath)\n",
    "            df['dateTime'] = pd.to_datetime(df['dateTime'])\n",
    "            df['station'] = df['station'].astype('category')\n",
    "            df['value'] = df['value'].astype('float32')\n",
    "        else:\n",
    "            print(f\"Downloading {measure.value} data on: {river}\")\n",
    "            df = self.batch_get_measure_on_river(measure, river)\n",
    "        df = self.update_dataframe(df, measure, river)\n",
    "        df.to_parquet(filepath)\n",
    "        return df\n",
    "\n",
    "def process_hydrology_data(df):\n",
    "    return df[df['quality'].isin(['Good', 'Unchecked', 'Estimated'])] \\\n",
    "        .pivot(index='dateTime', columns='station', values='value') \\\n",
    "        .resample('15min').interpolate('time', limit_direction='both', limit=2)\n",
    "        \n",
    "\n",
    "api = HydrologyApi(max_threads = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/river_wear_level_raw.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating data for station: Chester Le Street\n",
      "Got 49 new measurements\n",
      "Updating data for station: Witton Park\n",
      "Got 49 new measurements\n",
      "Updating data for station: Sunderland Bridge\n",
      "Got 49 new measurements\n",
      "Updating data for station: Stanhope\n",
      "Got 49 new measurements\n",
      "Updating data for station: Durham New Elvet Bridge\n",
      "Got 49 new measurements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>value</th>\n",
       "      <th>quality</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2023-11-02 11:00:00</td>\n",
       "      <td>1.403</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Durham New Elvet Bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>2023-11-02 11:15:00</td>\n",
       "      <td>1.464</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Durham New Elvet Bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2023-11-02 11:30:00</td>\n",
       "      <td>1.502</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Durham New Elvet Bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2023-11-02 11:45:00</td>\n",
       "      <td>1.540</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Durham New Elvet Bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2023-11-02 12:00:00</td>\n",
       "      <td>1.574</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Durham New Elvet Bridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dateTime  value    quality                  station\n",
       "1247 2023-11-02 11:00:00  1.403  Unchecked  Durham New Elvet Bridge\n",
       "1248 2023-11-02 11:15:00  1.464  Unchecked  Durham New Elvet Bridge\n",
       "1249 2023-11-02 11:30:00  1.502  Unchecked  Durham New Elvet Bridge\n",
       "1250 2023-11-02 11:45:00  1.540  Unchecked  Durham New Elvet Bridge\n",
       "1251 2023-11-02 12:00:00  1.574  Unchecked  Durham New Elvet Bridge"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_df = api.load(Measure.LEVEL, \"River Wear\")\n",
    "level_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>station</th>\n",
       "      <th>Chester Le Street</th>\n",
       "      <th>Durham New Elvet Bridge</th>\n",
       "      <th>Stanhope</th>\n",
       "      <th>Sunderland Bridge</th>\n",
       "      <th>Witton Park</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-11-02 11:00:00</th>\n",
       "      <td>1.303</td>\n",
       "      <td>1.403</td>\n",
       "      <td>1.097</td>\n",
       "      <td>1.236</td>\n",
       "      <td>1.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02 11:15:00</th>\n",
       "      <td>1.330</td>\n",
       "      <td>1.464</td>\n",
       "      <td>1.132</td>\n",
       "      <td>1.259</td>\n",
       "      <td>1.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02 11:30:00</th>\n",
       "      <td>1.357</td>\n",
       "      <td>1.502</td>\n",
       "      <td>1.162</td>\n",
       "      <td>1.272</td>\n",
       "      <td>1.441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02 11:45:00</th>\n",
       "      <td>1.386</td>\n",
       "      <td>1.540</td>\n",
       "      <td>1.216</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02 12:00:00</th>\n",
       "      <td>1.416</td>\n",
       "      <td>1.574</td>\n",
       "      <td>1.276</td>\n",
       "      <td>1.308</td>\n",
       "      <td>1.538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "station              Chester Le Street  Durham New Elvet Bridge  Stanhope  \\\n",
       "dateTime                                                                    \n",
       "2023-11-02 11:00:00              1.303                    1.403     1.097   \n",
       "2023-11-02 11:15:00              1.330                    1.464     1.132   \n",
       "2023-11-02 11:30:00              1.357                    1.502     1.162   \n",
       "2023-11-02 11:45:00              1.386                    1.540     1.216   \n",
       "2023-11-02 12:00:00              1.416                    1.574     1.276   \n",
       "\n",
       "station              Sunderland Bridge  Witton Park  \n",
       "dateTime                                             \n",
       "2023-11-02 11:00:00              1.236        1.357  \n",
       "2023-11-02 11:15:00              1.259        1.402  \n",
       "2023-11-02 11:30:00              1.272        1.441  \n",
       "2023-11-02 11:45:00              1.289        1.482  \n",
       "2023-11-02 12:00:00              1.308        1.538  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_df.pipe(process_hydrology_data).tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('COMP2271_DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e118ba02d0d63f0776027b45aa6c2794efdfedf6985533f6e5e4217ae01154a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode\n",
    "import urllib3\n",
    "import json\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "from io import StringIO\n",
    "import os\n",
    "from typing import Literal\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measure(Enum):\n",
    "    LEVEL = 'level'\n",
    "    RAINFALL = 'rainfall'\n",
    "\n",
    "class HydrologyApi:\n",
    "    API_BASE_URL = \"https://environment.data.gov.uk/hydrology/\"\n",
    "    DATA_DIR = \"data\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.http = urllib3.PoolManager()\n",
    "    \n",
    "    def get_stations_on_river(self, river):\n",
    "        api_url = self.API_BASE_URL + 'id/stations'\n",
    "        result = urlopen(\n",
    "            api_url + '?' + urlencode({'riverName': river})).read().decode('utf-8')\n",
    "        data = json.loads(result)\n",
    "        return pd.DataFrame(data['items'])\n",
    "    \n",
    "    def get_levels(self, station_id, start):\n",
    "        api_url = self.API_BASE_URL + f\"id/measures/{station_id}-level-i-900-m-qualified/readings\"\n",
    "        # result = urlopen(api_url).read().decode('utf-8')\n",
    "        result = self.http.request(\n",
    "            'GET',\n",
    "            api_url,\n",
    "            fields={\n",
    "                'mineq-date': start.strftime('%Y-%m-%d')             \n",
    "            }\n",
    "        ).data.decode('utf-8')\n",
    "        \n",
    "        data = json.loads(result)\n",
    "        return pd.DataFrame(data['items'])\n",
    "    \n",
    "    def _batch_request(self, api_url, query_params):\n",
    "        status = \"Pending\"\n",
    "\n",
    "        while status in (\"Pending\", \"InProgress\"):\n",
    "            \n",
    "            request = self.http.request(\n",
    "                'GET', \n",
    "                api_url, \n",
    "                headers={\n",
    "                    'Accept-Encoding': 'gzip'\n",
    "                }, \n",
    "                # fields=query_params\n",
    "            )\n",
    "            content_type = request.headers['Content-Type']\n",
    "\n",
    "            if content_type == 'text/csv':\n",
    "                if len(request.data) == 0:\n",
    "                    print('Got empty CSV')\n",
    "                    return None\n",
    "                buffer = StringIO(request.data.decode('utf-8'))\n",
    "                return pd.read_csv(buffer, low_memory=False)\n",
    "            \n",
    "            assert content_type in (\n",
    "                'application/json',\n",
    "                'application/json;charset=UTF-8'), f\"Unexpected content type: {content_type}\"\n",
    "\n",
    "            data = json.loads(request.data.decode('utf-8'))\n",
    "            status = data[\"status\"]\n",
    "\n",
    "            if status == \"Pending\":\n",
    "                print(f\"Query is pending\")\n",
    "                pos_in_queue = data[\"positionInQueue\"]\n",
    "                print(f\"Position in queue: {pos_in_queue}\")\n",
    "                eta = data[\"eta\"] / 1000\n",
    "                print(f\"Estimated completion: {eta}\")\n",
    "                sleep(eta * 1.1)\n",
    "\n",
    "            elif status == \"InProgress\":\n",
    "                print(f\"Query in progress\")\n",
    "                eta = data[\"eta\"] / 1000\n",
    "                print(f\"Estimated completion: {eta}\")\n",
    "                sleep(eta * 1.1)\n",
    "\n",
    "            elif status in (\"Complete\", \"Completed\"):\n",
    "                print(f\"Query completed: {data}\")\n",
    "                csv_url = data[\"dataUrl\"] if \"dataUrl\" in data else data[\"url\"]\n",
    "                return pd.read_csv(csv_url, low_memory=False)\n",
    "\n",
    "            elif status == \"Failed\":\n",
    "                raise Exception(f\"Query failed, response: {data}\")\n",
    "\n",
    "            else:\n",
    "                raise Exception(f\"Unknown status: {data['status']}\")\n",
    "        \n",
    "    \n",
    "    def batch_get_levels(self, station_id, start_date=None):\n",
    "        api_url = self.API_BASE_URL + \\\n",
    "            f\"data/batch-readings/batch/?measure={station_id}-level-i-900-m-qualified\"\n",
    "            \n",
    "        return self._batch_request(api_url, {\n",
    "            'mineq-date': start_date\n",
    "        } if start_date else {})\n",
    "            \n",
    "    def batch_get_rainfall(self, station_id, start_date=None):\n",
    "        api_url = self.API_BASE_URL + \\\n",
    "            f\"data/batch-readings/batch/?measure={station_id}-rainfall-i-900\"\n",
    "            \n",
    "        return self._batch_request(api_url, {\n",
    "            'mineq-date': start_date\n",
    "        } if start_date else {})\n",
    "    \n",
    "    def batch_get_measure(self, measure: Measure, station_id, start_date=None):\n",
    "        return {\n",
    "            Measure.LEVEL: self.batch_get_levels,\n",
    "            Measure.RAINFALL: self.batch_get_rainfall\n",
    "        }[measure](station_id, start_date)\n",
    "        \n",
    "    def batch_get_measure_on_river(self, measure: Measure, river, start_date=None):\n",
    "        data = pd.DataFrame()\n",
    "        for station_id, station_name in self.get_stations_on_river(river)[['notation', 'label']].values:\n",
    "            print(f\"Downloading {measure.value} data for station: {station_name}\")\n",
    "            new_data = self.batch_get_measure(measure, station_id, start_date)\n",
    "            if new_data is None:\n",
    "                print(f\"No new data for station: {station_name}\")\n",
    "                continue\n",
    "            new_data = new_data.drop(columns=['measure', 'date', 'qcode', 'completeness'])\n",
    "            new_data['station'] = station_name\n",
    "            new_data['station'] = new_data['station'].astype('category')\n",
    "            new_data['dateTime'] = pd.to_datetime(new_data['dateTime'])\n",
    "            new_data['value'] = new_data['value'].astype('float32')\n",
    "            new_data['quality'] = new_data['quality'].astype('category')\n",
    "            data = pd.concat([data, new_data])\n",
    "            data.drop_duplicates(subset=['dateTime', 'station'], inplace=True)\n",
    "        return data\n",
    "        \n",
    "    def get_filename(self, measure: Measure, river):\n",
    "        return f\"{river.lower().replace(' ', '_')}_{measure.value}_raw.parquet\"\n",
    "        \n",
    "    def update_dataframe(self, df: pd.DataFrame, measure: Measure, river: str):\n",
    "        # last_date = df['dateTime'].max()\n",
    "        # if last_date >= pd.to_datetime('today'):\n",
    "        #     print(f\"Data is up to date\")\n",
    "        #     return df\n",
    "        # df = pd.concat([df, self.batch_get_measure_on_river(measure, river, last_date.strftime('%Y-%m-%d'))])\n",
    "        # df.drop_duplicates(subset=['dateTime', 'station'], inplace=True)\n",
    "        # return df\n",
    "        assert measure == Measure.LEVEL\n",
    "        for station_name, station_id in self.get_stations_on_river(river)[['label', 'notation']].values:\n",
    "            print(f\"Updating data for station: {station_name}\")\n",
    "            last = df[df['station'] == station_name]['dateTime'].max()\n",
    "            new_measurements = self.get_levels(station_id, last)[['dateTime', 'value', 'quality']]\n",
    "            new_measurements['station'] = station_name\n",
    "            new_measurements['station'] = new_measurements['station'].astype('category')\n",
    "            new_measurements['dateTime'] = pd.to_datetime(new_measurements['dateTime'])\n",
    "            new_measurements['value'] = new_measurements['value'].astype('float32')\n",
    "            print(f\"Got {len(new_measurements)} new measurements\")\n",
    "            df = pd.concat([df, new_measurements])\n",
    "        df.drop_duplicates(subset=['dateTime', 'station'], inplace=True)\n",
    "        return df\n",
    "            \n",
    "    def load(self, measure: Measure, river):\n",
    "        filename = self.get_filename(measure, river)\n",
    "        filepath = os.path.join(self.DATA_DIR, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"Loading {filepath}\")\n",
    "            df = pd.read_parquet(filepath)\n",
    "            df['dateTime'] = pd.to_datetime(df['dateTime'])\n",
    "            df['station'] = df['station'].astype('category')\n",
    "            df['value'] = df['value'].astype('float32')\n",
    "            df = self.update_dataframe(df, measure, river)\n",
    "        else:\n",
    "            print(f\"Downloading {measure.value} data on: {river}\")\n",
    "            df = self.batch_get_measure_on_river(measure, river)\n",
    "        df.to_parquet(filepath)\n",
    "        return df\n",
    "\n",
    "def process_hydrology_data(df):\n",
    "    return df[df['quality'].isin(['Good', 'Unchecked', 'Estimated'])] \\\n",
    "        .drop(columns=['completeness']) \\\n",
    "        .pivot(index='dateTime', columns='station', values='value') \\\n",
    "        .resample('15min').interpolate('time', limit_direction='both', limit=2)\n",
    "        \n",
    "\n",
    "api = HydrologyApi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/river_wear_level_raw.parquet\n",
      "Updating data for station: Chester Le Street\n",
      "Got 1252 new measurements\n",
      "Updating data for station: Witton Park\n",
      "Got 1252 new measurements\n",
      "Updating data for station: Sunderland Bridge\n",
      "Got 1252 new measurements\n",
      "Updating data for station: Stanhope\n",
      "Got 1252 new measurements\n",
      "Updating data for station: Durham New Elvet Bridge\n",
      "Got 1252 new measurements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>value</th>\n",
       "      <th>completeness</th>\n",
       "      <th>quality</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981-09-29 10:00:00</td>\n",
       "      <td>0.443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Chester Le Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981-09-29 04:00:00</td>\n",
       "      <td>0.440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Chester Le Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981-09-29 04:15:00</td>\n",
       "      <td>0.440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Chester Le Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1981-09-29 04:30:00</td>\n",
       "      <td>0.440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Chester Le Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1981-09-29 04:45:00</td>\n",
       "      <td>0.440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Chester Le Street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dateTime  value  completeness    quality            station\n",
       "0 1981-09-29 10:00:00  0.443           NaN  Unchecked  Chester Le Street\n",
       "1 1981-09-29 04:00:00  0.440           NaN  Unchecked  Chester Le Street\n",
       "2 1981-09-29 04:15:00  0.440           NaN  Unchecked  Chester Le Street\n",
       "3 1981-09-29 04:30:00  0.440           NaN  Unchecked  Chester Le Street\n",
       "4 1981-09-29 04:45:00  0.440           NaN  Unchecked  Chester Le Street"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_df = api.load(Measure.LEVEL, \"River Wear\")\n",
    "level_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTime</th>\n",
       "      <th>value</th>\n",
       "      <th>completeness</th>\n",
       "      <th>quality</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1961-01-29 01:00:00</td>\n",
       "      <td>0.610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Stanhope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1961-01-29 01:15:00</td>\n",
       "      <td>0.610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Stanhope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1961-01-29 01:30:00</td>\n",
       "      <td>0.610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Stanhope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1961-01-29 01:45:00</td>\n",
       "      <td>0.610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Stanhope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1961-01-29 02:00:00</td>\n",
       "      <td>0.610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unchecked</td>\n",
       "      <td>Stanhope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2023-11-02 12:00:00</td>\n",
       "      <td>1.416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chester Le Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2023-11-02 12:00:00</td>\n",
       "      <td>1.308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunderland Bridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2023-11-02 12:00:00</td>\n",
       "      <td>1.538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Witton Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2023-11-02 12:00:00</td>\n",
       "      <td>1.276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stanhope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>2023-11-02 12:00:00</td>\n",
       "      <td>1.574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Durham New Elvet Bridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6641062 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                dateTime  value  completeness    quality  \\\n",
       "0    1961-01-29 01:00:00  0.610           NaN  Unchecked   \n",
       "1    1961-01-29 01:15:00  0.610           NaN  Unchecked   \n",
       "2    1961-01-29 01:30:00  0.610           NaN  Unchecked   \n",
       "3    1961-01-29 01:45:00  0.610           NaN  Unchecked   \n",
       "4    1961-01-29 02:00:00  0.610           NaN  Unchecked   \n",
       "...                  ...    ...           ...        ...   \n",
       "1251 2023-11-02 12:00:00  1.416           NaN        NaN   \n",
       "1251 2023-11-02 12:00:00  1.308           NaN        NaN   \n",
       "1251 2023-11-02 12:00:00  1.538           NaN        NaN   \n",
       "1251 2023-11-02 12:00:00  1.276           NaN        NaN   \n",
       "1251 2023-11-02 12:00:00  1.574           NaN        NaN   \n",
       "\n",
       "                      station  \n",
       "0                    Stanhope  \n",
       "1                    Stanhope  \n",
       "2                    Stanhope  \n",
       "3                    Stanhope  \n",
       "4                    Stanhope  \n",
       "...                       ...  \n",
       "1251        Chester Le Street  \n",
       "1251        Sunderland Bridge  \n",
       "1251              Witton Park  \n",
       "1251                 Stanhope  \n",
       "1251  Durham New Elvet Bridge  \n",
       "\n",
       "[6641062 rows x 5 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_df.sort_values(by='dateTime', inplace=True)\n",
    "level_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating data for station: Chester Le Street\n",
      "Got 1252 new measurements\n",
      "Updating data for station: Witton Park\n",
      "Got 1252 new measurements\n",
      "Updating data for station: Sunderland Bridge\n",
      "Got 1252 new measurements\n",
      "Updating data for station: Stanhope\n",
      "Got 1252 new measurements\n",
      "Updating data for station: Durham New Elvet Bridge\n",
      "Got 1252 new measurements\n"
     ]
    }
   ],
   "source": [
    "level_df = api.update_dataframe(level_df, Measure.LEVEL, \"River Wear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-10-20 21:30:00')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_df.dateTime.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>station</th>\n",
       "      <th>Chester Le Street</th>\n",
       "      <th>Durham New Elvet Bridge</th>\n",
       "      <th>Stanhope</th>\n",
       "      <th>Sunderland Bridge</th>\n",
       "      <th>Witton Park</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-10-18 13:00:00</th>\n",
       "      <td>0.307</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-18 13:15:00</th>\n",
       "      <td>0.313</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-18 13:30:00</th>\n",
       "      <td>0.313</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-18 13:45:00</th>\n",
       "      <td>0.314</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-10-18 14:00:00</th>\n",
       "      <td>0.312</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "station              Chester Le Street  Durham New Elvet Bridge  Stanhope  \\\n",
       "dateTime                                                                    \n",
       "2005-10-18 13:00:00              0.307                    0.248     0.162   \n",
       "2005-10-18 13:15:00              0.313                    0.248     0.160   \n",
       "2005-10-18 13:30:00              0.313                    0.248     0.160   \n",
       "2005-10-18 13:45:00              0.314                    0.248     0.161   \n",
       "2005-10-18 14:00:00              0.312                    0.248     0.160   \n",
       "\n",
       "station              Sunderland Bridge  Witton Park  \n",
       "dateTime                                             \n",
       "2005-10-18 13:00:00              0.307        0.372  \n",
       "2005-10-18 13:15:00              0.312        0.372  \n",
       "2005-10-18 13:30:00              0.310        0.371  \n",
       "2005-10-18 13:45:00              0.310        0.371  \n",
       "2005-10-18 14:00:00              0.309        0.371  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_df = process_hydrology_data(level_df)\n",
    "level_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 463280 entries, 2005-10-18 13:00:00 to 2023-08-08 10:45:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   Chester Le Street        463280 non-null  float32\n",
      " 1   Durham New Elvet Bridge  463280 non-null  float32\n",
      " 2   Stanhope                 463280 non-null  float32\n",
      " 3   Sunderland Bridge        463280 non-null  float32\n",
      " 4   Witton Park              463280 non-null  float32\n",
      "dtypes: float32(5)\n",
      "memory usage: 12.4 MB\n"
     ]
    }
   ],
   "source": [
    "level_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df.to_parquet('data/river_wear_level.parquet')\n",
    "del level_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading rainfall data on: River Wear\n",
      "Downloading rainfall data for station: Chester Le Street\n",
      "Query in progress\n",
      "Estimated completion: 59.929\n",
      "No new data for station: Chester Le Street\n",
      "Downloading rainfall data for station: Witton Park\n",
      "Query in progress\n",
      "Estimated completion: 59.993\n",
      "No new data for station: Witton Park\n",
      "Downloading rainfall data for station: Sunderland Bridge\n",
      "Query in progress\n",
      "Estimated completion: 59.963\n",
      "No new data for station: Sunderland Bridge\n",
      "Downloading rainfall data for station: Stanhope\n",
      "Query in progress\n",
      "Estimated completion: 59.916\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ed/code/river-level-analysis/build_datasets.ipynb Cell 6\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m rainfall_df \u001b[39m=\u001b[39m api\u001b[39m.\u001b[39;49mload(Measure\u001b[39m.\u001b[39;49mRAINFALL, \u001b[39m\"\u001b[39;49m\u001b[39mRiver Wear\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rainfall_df\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;32m/home/ed/code/river-level-analysis/build_datasets.ipynb Cell 6\u001b[0m line \u001b[0;36mHydrologyApi.load\u001b[0;34m(self, measure, river)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m{\u001b[39;00mmeasure\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m data on: \u001b[39m\u001b[39m{\u001b[39;00mriver\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_get_measure_on_river(measure, river)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m df\u001b[39m.\u001b[39mto_parquet(filepath)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "\u001b[1;32m/home/ed/code/river-level-analysis/build_datasets.ipynb Cell 6\u001b[0m line \u001b[0;36mHydrologyApi.batch_get_measure_on_river\u001b[0;34m(self, measure, river, start_date)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39mfor\u001b[39;00m station_id, station_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_stations_on_river(river)[[\u001b[39m'\u001b[39m\u001b[39mnotation\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m{\u001b[39;00mmeasure\u001b[39m.\u001b[39mvalue\u001b[39m}\u001b[39;00m\u001b[39m data for station: \u001b[39m\u001b[39m{\u001b[39;00mstation_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_get_measure(measure, station_id, start_date)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     \u001b[39mif\u001b[39;00m new_data\u001b[39m.\u001b[39mempty:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo new data for station: \u001b[39m\u001b[39m{\u001b[39;00mstation_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/ed/code/river-level-analysis/build_datasets.ipynb Cell 6\u001b[0m line \u001b[0;36mHydrologyApi.batch_get_measure\u001b[0;34m(self, measure, station_id, start_date)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_get_measure\u001b[39m(\u001b[39mself\u001b[39m, measure: Measure, station_id, start_date\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m         Measure\u001b[39m.\u001b[39;49mLEVEL: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_get_levels,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m         Measure\u001b[39m.\u001b[39;49mRAINFALL: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_get_rainfall\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m     }[measure](station_id, start_date)\n",
      "\u001b[1;32m/home/ed/code/river-level-analysis/build_datasets.ipynb Cell 6\u001b[0m line \u001b[0;36mHydrologyApi.batch_get_rainfall\u001b[0;34m(self, station_id, start_date)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbatch_get_rainfall\u001b[39m(\u001b[39mself\u001b[39m, station_id, start_date\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     api_url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mAPI_BASE_URL \u001b[39m+\u001b[39m \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/batch-readings/batch/?measure=\u001b[39m\u001b[39m{\u001b[39;00mstation_id\u001b[39m}\u001b[39;00m\u001b[39m-rainfall-i-900\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_request(api_url, {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mmineq-date\u001b[39;49m\u001b[39m'\u001b[39;49m: start_date\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m     } \u001b[39mif\u001b[39;49;00m start_date \u001b[39melse\u001b[39;49;00m {})\n",
      "\u001b[1;32m/home/ed/code/river-level-analysis/build_datasets.ipynb Cell 6\u001b[0m line \u001b[0;36mHydrologyApi._batch_request\u001b[0;34m(self, api_url, query_params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m status \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPending\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mwhile\u001b[39;00m status \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mPending\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mInProgress\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhttp\u001b[39m.\u001b[39;49mrequest(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, api_url, headers\u001b[39m=\u001b[39;49m{\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mAccept-Encoding\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mgzip\u001b[39;49m\u001b[39m'\u001b[39;49m}, fields\u001b[39m=\u001b[39;49mquery_params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     content_type \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mheaders[\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ed/code/river-level-analysis/build_datasets.ipynb#X24sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mif\u001b[39;00m content_type \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtext/csv\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/request.py:74\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m urlopen_kw[\u001b[39m\"\u001b[39m\u001b[39mrequest_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m url\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_url_methods:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/request.py:96\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m fields:\n\u001b[1;32m     94\u001b[0m     url \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m urlencode(fields)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/poolmanager.py:375\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    373\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 375\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    377\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:699\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    698\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    700\u001b[0m     conn,\n\u001b[1;32m    701\u001b[0m     method,\n\u001b[1;32m    702\u001b[0m     url,\n\u001b[1;32m    703\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    704\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    705\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    706\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    707\u001b[0m )\n\u001b[1;32m    709\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    713\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:445\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    440\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    441\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    446\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    447\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:440\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    441\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1376\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rainfall_df = api.load(Measure.RAINFALL, \"River Wear\")\n",
    "rainfall_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df = process_hydrology_data(rainfall_df)\n",
    "rainfall_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_df.to_parquet('data/river_wear_rainfall.parquet')\n",
    "del rainfall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the data is classed as good, so we can drop rows that arn't."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('COMP2271_DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e118ba02d0d63f0776027b45aa6c2794efdfedf6985533f6e5e4217ae01154a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

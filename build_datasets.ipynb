{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlencode\n",
    "import urllib3\n",
    "import json\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from io import StringIO\n",
    "import os\n",
    "from enum import Enum\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydrology API code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measure(Enum):\n",
    "    LEVEL = 'level'\n",
    "    FLOW = 'flow'\n",
    "    RAINFALL = 'rainfall'\n",
    "\n",
    "class HydrologyApi:\n",
    "    API_BASE_URL = \"https://environment.data.gov.uk/hydrology/\"\n",
    "    DATA_DIR = \"data\"\n",
    "    \n",
    "    float_precision = np.float16\n",
    "    \n",
    "    units = {\n",
    "        Measure.LEVEL: 'i-900-m-qualified',\n",
    "        Measure.FLOW: 'i-900-m3s-qualified',\n",
    "        Measure.RAINFALL: 't-900-mm-qualified',\n",
    "    }\n",
    "    \n",
    "    def __init__(self, max_threads):\n",
    "        self.http = urllib3.PoolManager(maxsize=max_threads)\n",
    "        self.thread_pool = ThreadPoolExecutor(max_workers=max_threads)\n",
    "    \n",
    "    def get_stations_on_river(self, river):\n",
    "        api_url = self.API_BASE_URL + 'id/stations'\n",
    "        result = urlopen(\n",
    "            api_url + '?' + urlencode({'riverName': river})).read().decode('utf-8')\n",
    "        data = json.loads(result)\n",
    "        return pd.DataFrame(data['items'])\n",
    "        \n",
    "    def get_stations_close_to_with_measure(self, lat, lon, radius, measure: Measure, limit=100):\n",
    "        api_url = self.API_BASE_URL + 'id/stations'\n",
    "        \n",
    "        result = self.http.request(\n",
    "            'GET',\n",
    "            api_url,\n",
    "            fields={\n",
    "                'observedProperty': measure.value,\n",
    "                'lat': lat,\n",
    "                'long': lon,\n",
    "                'dist': radius,\n",
    "                'status.label':'Active',\n",
    "                '_limit': limit\n",
    "            }\n",
    "        ).data.decode('utf-8')\n",
    "        data = json.loads(result)\n",
    "        return pd.DataFrame(data['items'])\n",
    "        \n",
    "    \n",
    "    def get_measure(self, measure: Measure, station_id: str, start=None):\n",
    "        api_url = self.API_BASE_URL + f\"id/measures/{station_id}-{measure.value}-{HydrologyApi.units[measure]}/readings\"\n",
    "        # result = urlopen(api_url).read().decode('utf-8')\n",
    "        result = self.http.request(\n",
    "            'GET',\n",
    "            api_url,\n",
    "            fields={}\n",
    "                | ({\n",
    "                    'mineq-date': start.strftime('%Y-%m-%d')\n",
    "                } if start is not None else {}),\n",
    "        ).data.decode('utf-8')\n",
    "        data = json.loads(result)\n",
    "        return pd.DataFrame(data['items'])\n",
    "    \n",
    "    def _batch_request(self, api_url):\n",
    "        status = \"Pending\"\n",
    "\n",
    "        while status in (\"Pending\", \"InProgress\"):\n",
    "            print(f\"Making request to: {api_url}\")\n",
    "            \n",
    "            request = self.http.request(\n",
    "                'GET', \n",
    "                api_url, \n",
    "                headers={\n",
    "                    'Accept-Encoding': 'gzip'\n",
    "                }\n",
    "            )\n",
    "            content_type = request.headers['Content-Type']\n",
    "\n",
    "            if content_type == 'text/csv':\n",
    "                if len(request.data) == 0:\n",
    "                    print('Got empty CSV')\n",
    "                    return None\n",
    "                buffer = StringIO(request.data.decode('utf-8'))\n",
    "                return pd.read_csv(buffer, low_memory=False)\n",
    "            \n",
    "            assert content_type in (\n",
    "                'application/json',\n",
    "                'application/json;charset=UTF-8'), f\"Unexpected content type: {content_type}\"\n",
    "\n",
    "            data = json.loads(request.data.decode('utf-8'))\n",
    "            status = data[\"status\"]\n",
    "\n",
    "            if status == \"Pending\":\n",
    "                print(f\"Query is pending\")\n",
    "                pos_in_queue = data[\"positionInQueue\"]\n",
    "                print(f\"Position in queue: {pos_in_queue}\")\n",
    "                eta = data[\"eta\"] / 1000\n",
    "                print(f\"Estimated completion: {eta}\")\n",
    "                sleep(eta * 1.1)\n",
    "\n",
    "            elif status == \"InProgress\":\n",
    "                print(f\"Query in progress\")\n",
    "                eta = data[\"eta\"] / 1000\n",
    "                print(f\"Estimated completion: {eta}\")\n",
    "                sleep(eta * 1.1)\n",
    "\n",
    "            elif status in (\"Complete\", \"Completed\"):\n",
    "                print(f\"Query completed: {data}\")\n",
    "                csv_url = data[\"dataUrl\"] if \"dataUrl\" in data else data[\"url\"]\n",
    "                return pd.read_csv(csv_url)\n",
    "\n",
    "            elif status == \"Failed\":\n",
    "                raise Exception(f\"Query failed, response: {data}\")\n",
    "\n",
    "            else:\n",
    "                raise Exception(f\"Unknown status: {data['status']}\")\n",
    "    \n",
    "    def batch_get_measure(self, measure: Measure, station_id):\n",
    "        try:\n",
    "            api_url = self.API_BASE_URL + \\\n",
    "                f\"data/batch-readings/batch/?measure={station_id}-{measure.value}-{HydrologyApi.units[measure]}\"\n",
    "                \n",
    "            return self._batch_request(api_url)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to get data for station: {station_id}, {e}\")\n",
    "            return None\n",
    "        \n",
    "    def batch_get_measure_on_river(self, measure: Measure, river):\n",
    "        stations = self.get_stations_on_river(river)\n",
    "        return self.batch_get_measure_from_stations(measure, stations)\n",
    "        \n",
    "    def batch_get_measure_from_stations(self, measure: Measure, stations):\n",
    "        data = pd.DataFrame()\n",
    "        threads = [\n",
    "            self.thread_pool.submit(\n",
    "                self.batch_get_measure, measure, station_id)\n",
    "            for station_id in stations['notation'].values\n",
    "        ]\n",
    "        \n",
    "        for thread, (station_id, station_name) in zip(threads, stations[['notation', 'label']].values):\n",
    "            new_data = thread.result()\n",
    "            if new_data is None:\n",
    "                print(f\"No new data for station: {station_name}\")\n",
    "                continue\n",
    "            new_data = new_data.drop(columns=['measure', 'date', 'qcode', 'completeness'])\n",
    "            new_data['station'] = station_name\n",
    "            new_data['station'] = new_data['station'].astype('category')\n",
    "            new_data['dateTime'] = pd.to_datetime(new_data['dateTime'])\n",
    "            new_data['value'] = new_data['value'].astype(float)\n",
    "            new_data['quality'] = new_data['quality'].astype('category')\n",
    "            data = pd.concat([data, new_data])\n",
    "            data.drop_duplicates(subset=['dateTime', 'station'], inplace=True)\n",
    "        return data\n",
    "        \n",
    "        \n",
    "    def get_filename(self, measure: Measure, river):\n",
    "        return f\"{river.lower().replace(' ', '_')}_{measure.value}_raw.feather\"\n",
    "        \n",
    "    def update_dataframe(self, df: pd.DataFrame, measure: Measure, river: str):\n",
    "        for station_name, station_id in self.get_stations_on_river(river)[['label', 'notation']].values:\n",
    "            print(f\"Updating data for station: {station_name}\")\n",
    "            last = df[df['station'] == station_name]['dateTime'].max() if len(df) > 0 else None\n",
    "            new_measurements = self.get_measure(measure, station_id, last)[['dateTime', 'value', 'quality']]\n",
    "            new_measurements['station'] = station_name\n",
    "            new_measurements['station'] = new_measurements['station'].astype('category')\n",
    "            new_measurements['dateTime'] = pd.to_datetime(new_measurements['dateTime'])\n",
    "            new_measurements['value'] = new_measurements['value'].astype(float)\n",
    "            print(f\"Got {len(new_measurements)} new measurements\")\n",
    "            df = pd.concat([df, new_measurements])\n",
    "        df.drop_duplicates(subset=['dateTime', 'station'], inplace=True)\n",
    "        return df\n",
    "            \n",
    "    def load(self, measure: Measure, river):\n",
    "        if not os.path.exists(self.DATA_DIR):\n",
    "            os.mkdir(self.DATA_DIR)\n",
    "        \n",
    "        filename = self.get_filename(measure, river)\n",
    "        filepath = os.path.join(self.DATA_DIR, filename)\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"Loading {filepath}\")\n",
    "            df = pd.read_feather(filepath)\n",
    "            df['dateTime'] = pd.to_datetime(df['dateTime'])\n",
    "            df['station'] = df['station'].astype('category')\n",
    "            df['value'] = df['value'].astype(float)\n",
    "        else:\n",
    "            print(f\"Downloading {measure.value} data on: {river}\")\n",
    "            df = self.batch_get_measure_on_river(measure, river)\n",
    "            df.to_feather(filepath)\n",
    "        try:\n",
    "            df = self.update_dataframe(df, measure, river)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to update data: {e}\")\n",
    "        df.to_feather(filepath)\n",
    "        return df\n",
    "\n",
    "def process_hydrology_data(df):\n",
    "    return df[df['quality'].isin(['Good', 'Unchecked', 'Estimated'])] \\\n",
    "        .pivot(index='dateTime', columns='station', values='value') \\\n",
    "        .resample('15min').interpolate('time', limit_direction='both', limit=2, fill_value='extrapolate') \\\n",
    "        .astype(np.float16)\n",
    "\n",
    "api = HydrologyApi(max_threads = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\\river_wear_level_raw.feather\n",
      "Updating data for station: Chester Le Street\n",
      "Got 4 new measurements\n",
      "Updating data for station: Witton Park\n",
      "Got 4 new measurements\n",
      "Updating data for station: Sunderland Bridge\n",
      "Got 4 new measurements\n",
      "Updating data for station: Stanhope\n",
      "Got 4 new measurements\n",
      "Updating data for station: Durham New Elvet Bridge\n",
      "Got 4 new measurements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\river-level\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2200800 entries, 1961-01-29 01:00:00 to 2023-11-05 00:45:00\n",
      "Freq: 15T\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   Chester Le Street        float16\n",
      " 1   Durham New Elvet Bridge  float16\n",
      " 2   Stanhope                 float16\n",
      " 3   Sunderland Bridge        float16\n",
      " 4   Witton Park              float16\n",
      "dtypes: float16(5)\n",
      "memory usage: 37.8 MB\n"
     ]
    }
   ],
   "source": [
    "level_df = api.load(Measure.LEVEL, \"River Wear\")\n",
    "level_df = process_hydrology_data(level_df)\n",
    "level_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Flow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\\river_wear_flow_raw.feather\n",
      "Updating data for station: Chester Le Street\n",
      "Got 25 new measurements\n",
      "Updating data for station: Witton Park\n",
      "Got 25 new measurements\n",
      "Updating data for station: Sunderland Bridge\n",
      "Got 25 new measurements\n",
      "Updating data for station: Stanhope\n",
      "Got 25 new measurements\n",
      "Updating data for station: Durham New Elvet Bridge\n",
      "Failed to update data: NaTType does not support strftime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\river-level\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2198709 entries, 1961-01-29 01:00:00 to 2023-10-14 06:00:00\n",
      "Freq: 15T\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Chester Le Street  float16\n",
      " 1   Stanhope           float16\n",
      " 2   Sunderland Bridge  float16\n",
      " 3   Witton Park        float16\n",
      "dtypes: float16(4)\n",
      "memory usage: 33.5 MB\n"
     ]
    }
   ],
   "source": [
    "flow_df = api.load(Measure.FLOW, \"River Wear\")\n",
    "flow_df = process_hydrology_data(flow_df)\n",
    "flow_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have flow data at New Elvet unfortunatly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Rainfall Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5 rainfall stations\n"
     ]
    }
   ],
   "source": [
    "rainfall_stations = api.get_stations_close_to_with_measure(54.66305556, -1.67611111, 15, Measure.RAINFALL, limit=10)\n",
    "bad_stations = ['15202aee-c5fd-404d-9de9-7357174ad10c']\n",
    "rainfall_stations = rainfall_stations[~rainfall_stations['notation'].isin(bad_stations)].head(5)\n",
    "print(f\"Using {len(rainfall_stations)} rainfall stations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making request to: https://environment.data.gov.uk/hydrology/data/batch-readings/batch/?measure=1dabd12c-1d2e-4765-ae38-a4d5a121928d-rainfall-t-900-mm-qualified\n",
      "Making request to: https://environment.data.gov.uk/hydrology/data/batch-readings/batch/?measure=bf61ce31-b20e-4593-85dc-a083133b12ce-rainfall-t-900-mm-qualified\n",
      "Making request to: https://environment.data.gov.uk/hydrology/data/batch-readings/batch/?measure=bc34e640-d9ae-4362-8804-25d66ca66e4d-rainfall-t-900-mm-qualified\n",
      "Making request to: https://environment.data.gov.uk/hydrology/data/batch-readings/batch/?measure=051f1b2a-6aca-4402-8956-5474ad39b12a-rainfall-t-900-mm-qualified\n",
      "Making request to: https://environment.data.gov.uk/hydrology/data/batch-readings/batch/?measure=a8773476-0fde-40c7-a66b-0901e528e8f2-rainfall-t-900-mm-qualified\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1467087 entries, 1982-01-01 09:15:00 to 2023-11-04 12:45:00\n",
      "Freq: 15T\n",
      "Data columns (total 5 columns):\n",
      " #   Column                    Non-Null Count    Dtype  \n",
      "---  ------                    --------------    -----  \n",
      " 0   Copley                    910801 non-null   float16\n",
      " 1   Darlington Lingfield Way  1058363 non-null  float16\n",
      " 2   Evenwood Gate             853165 non-null   float16\n",
      " 3   Harpington Hill Farm      1192013 non-null  float16\n",
      " 4   Tunstall                  1417394 non-null  float16\n",
      "dtypes: float16(5)\n",
      "memory usage: 25.2 MB\n"
     ]
    }
   ],
   "source": [
    "rainfall_df = api.batch_get_measure_from_stations(Measure.RAINFALL, rainfall_stations)\n",
    "rainfall_df = process_hydrology_data(rainfall_df)\n",
    "rainfall_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 351726 entries, 1999-12-03 20:30:00 to 2023-10-14 06:00:00\n",
      "Data columns (total 14 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   Level Chester Le Street            351726 non-null  float16\n",
      " 1   Level Durham New Elvet Bridge      351726 non-null  float16\n",
      " 2   Level Stanhope                     351726 non-null  float16\n",
      " 3   Level Sunderland Bridge            351726 non-null  float16\n",
      " 4   Level Witton Park                  351726 non-null  float16\n",
      " 5   Flow Chester Le Street             351726 non-null  float16\n",
      " 6   Flow Stanhope                      351726 non-null  float16\n",
      " 7   Flow Sunderland Bridge             351726 non-null  float16\n",
      " 8   Flow Witton Park                   351726 non-null  float16\n",
      " 9   Rainfall Copley                    351726 non-null  float16\n",
      " 10  Rainfall Darlington Lingfield Way  351726 non-null  float16\n",
      " 11  Rainfall Evenwood Gate             351726 non-null  float16\n",
      " 12  Rainfall Harpington Hill Farm      351726 non-null  float16\n",
      " 13  Rainfall Tunstall                  351726 non-null  float16\n",
      "dtypes: float16(14)\n",
      "memory usage: 12.1 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(\n",
    "    level_df.add_prefix('Level '),\n",
    "    flow_df.add_prefix('Flow '),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='outer',\n",
    ")\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    rainfall_df.add_prefix('Rainfall '),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='outer',\n",
    ").dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Lag Features\n",
    "for some reason makes loads of nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 475082 entries, 1999-11-26 00:00:00 to 2023-10-14 08:00:00\n",
      "Columns: 164 entries, Level Chester Le Street to Rainfall Tunstall -7d\n",
      "dtypes: float16(79), float32(85)\n",
      "memory usage: 229.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_rainfall_hourly = df.filter(regex='Rainfall').resample('1h').sum()\n",
    "df_rainfall_six_hourly = df.filter(regex='Rainfall').resample('6h').sum()\n",
    "df_rainfall_daily = df.filter(regex='Rainfall').resample('1d').sum()\n",
    "\n",
    "target_cols = ['Level Durham New Elvet Bridge']\n",
    "target_shifts = [+15, +30, +60, +90, +120]\n",
    "level_shifts = [-15, -30, -60, -90, -120]\n",
    "flow_shifts = [-15, -30, -60, -90, -120]\n",
    "rainfall_min_shifts = [-15, -30, -60]\n",
    "rainfall_hour_shifts = [-2, -3, -4, -5, -6]\n",
    "rainfall_six_hour_shifts = [-12, -18, -24, -30, -36, -42, -48]\n",
    "rainfall_day_shifts = [-3, -4, -5, -6, -7]\n",
    "\n",
    "output_target_cols = []\n",
    "\n",
    "df_lagged = df.copy()\n",
    "\n",
    "for shift in target_shifts:\n",
    "    shifted_df = df[target_cols].shift(shift, freq='min')\n",
    "    shifted_df = shifted_df.add_suffix(f' {shift:+d}min')\n",
    "    output_target_cols.extend(shifted_df.columns)\n",
    "    df_lagged = pd.concat([df_lagged, shifted_df], axis=1)\n",
    "\n",
    "for shift in level_shifts:\n",
    "    shifted_df = df.filter(regex='Level').shift(shift, freq='min')\n",
    "    df_lagged = pd.concat([df_lagged, shifted_df.add_suffix(f' {shift:+d}min')], axis=1)\n",
    "    \n",
    "for shift in flow_shifts:\n",
    "    shifted_df = df.filter(regex='Flow').shift(shift, freq='min')\n",
    "    df_lagged = pd.concat([df_lagged, shifted_df.add_suffix(f' {shift:+d}min')], axis=1)\n",
    "\n",
    "for shift in rainfall_min_shifts:\n",
    "    shifted_df = df.filter(regex='Rainfall').shift(shift, freq='min')\n",
    "    df_lagged = pd.concat([df_lagged, shifted_df.add_suffix(f' {shift:+d}min')], axis=1)\n",
    "    \n",
    "for shift in rainfall_hour_shifts:\n",
    "    shifted_df = df_rainfall_hourly.shift(shift, freq='h')\n",
    "    df_lagged = pd.concat([df_lagged, shifted_df.add_suffix(f' {shift:+d}h')], axis=1)\n",
    "    \n",
    "for shift in rainfall_six_hour_shifts:\n",
    "    shifted_df = df_rainfall_six_hourly.shift(shift, freq='h')\n",
    "    df_lagged = pd.concat([df_lagged, shifted_df.add_suffix(f' {shift:+d}h')], axis=1)\n",
    "    \n",
    "for shift in rainfall_day_shifts:\n",
    "    shifted_df = df_rainfall_daily.shift(shift, freq='d')\n",
    "    df_lagged = pd.concat([df_lagged, shifted_df.add_suffix(f' {shift:+d}d')], axis=1)\n",
    "    \n",
    "df_lagged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Level Durham New Elvet Bridge +15min',\n",
       " 'Level Durham New Elvet Bridge +30min',\n",
       " 'Level Durham New Elvet Bridge +60min',\n",
       " 'Level Durham New Elvet Bridge +90min',\n",
       " 'Level Durham New Elvet Bridge +120min']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>station</th>\n",
       "      <th>Level Chester Le Street</th>\n",
       "      <th>Level Durham New Elvet Bridge</th>\n",
       "      <th>Level Stanhope</th>\n",
       "      <th>Level Sunderland Bridge</th>\n",
       "      <th>Level Witton Park</th>\n",
       "      <th>Flow Chester Le Street</th>\n",
       "      <th>Flow Stanhope</th>\n",
       "      <th>Flow Sunderland Bridge</th>\n",
       "      <th>Flow Witton Park</th>\n",
       "      <th>Rainfall Copley</th>\n",
       "      <th>...</th>\n",
       "      <th>Rainfall Copley -6d</th>\n",
       "      <th>Rainfall Darlington Lingfield Way -6d</th>\n",
       "      <th>Rainfall Evenwood Gate -6d</th>\n",
       "      <th>Rainfall Harpington Hill Farm -6d</th>\n",
       "      <th>Rainfall Tunstall -6d</th>\n",
       "      <th>Rainfall Copley -7d</th>\n",
       "      <th>Rainfall Darlington Lingfield Way -7d</th>\n",
       "      <th>Rainfall Evenwood Gate -7d</th>\n",
       "      <th>Rainfall Harpington Hill Farm -7d</th>\n",
       "      <th>Rainfall Tunstall -7d</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dateTime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-11-26 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-27 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>2.799316</td>\n",
       "      <td>3.599121</td>\n",
       "      <td>2.799316</td>\n",
       "      <td>4.600098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-28 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399902</td>\n",
       "      <td>2.799316</td>\n",
       "      <td>3.599121</td>\n",
       "      <td>2.799316</td>\n",
       "      <td>4.600098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-29 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-11-30 00:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-14 07:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-14 07:15:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-14 07:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-14 07:45:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-14 08:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>475082 rows Ã— 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "station              Level Chester Le Street  Level Durham New Elvet Bridge  \\\n",
       "dateTime                                                                      \n",
       "1999-11-26 00:00:00                      NaN                            NaN   \n",
       "1999-11-27 00:00:00                      NaN                            NaN   \n",
       "1999-11-28 00:00:00                      NaN                            NaN   \n",
       "1999-11-29 00:00:00                      NaN                            NaN   \n",
       "1999-11-30 00:00:00                      NaN                            NaN   \n",
       "...                                      ...                            ...   \n",
       "2023-10-14 07:00:00                      NaN                            NaN   \n",
       "2023-10-14 07:15:00                      NaN                            NaN   \n",
       "2023-10-14 07:30:00                      NaN                            NaN   \n",
       "2023-10-14 07:45:00                      NaN                            NaN   \n",
       "2023-10-14 08:00:00                      NaN                            NaN   \n",
       "\n",
       "station              Level Stanhope  Level Sunderland Bridge  \\\n",
       "dateTime                                                       \n",
       "1999-11-26 00:00:00             NaN                      NaN   \n",
       "1999-11-27 00:00:00             NaN                      NaN   \n",
       "1999-11-28 00:00:00             NaN                      NaN   \n",
       "1999-11-29 00:00:00             NaN                      NaN   \n",
       "1999-11-30 00:00:00             NaN                      NaN   \n",
       "...                             ...                      ...   \n",
       "2023-10-14 07:00:00             NaN                      NaN   \n",
       "2023-10-14 07:15:00             NaN                      NaN   \n",
       "2023-10-14 07:30:00             NaN                      NaN   \n",
       "2023-10-14 07:45:00             NaN                      NaN   \n",
       "2023-10-14 08:00:00             NaN                      NaN   \n",
       "\n",
       "station              Level Witton Park  Flow Chester Le Street  Flow Stanhope  \\\n",
       "dateTime                                                                        \n",
       "1999-11-26 00:00:00                NaN                     NaN            NaN   \n",
       "1999-11-27 00:00:00                NaN                     NaN            NaN   \n",
       "1999-11-28 00:00:00                NaN                     NaN            NaN   \n",
       "1999-11-29 00:00:00                NaN                     NaN            NaN   \n",
       "1999-11-30 00:00:00                NaN                     NaN            NaN   \n",
       "...                                ...                     ...            ...   \n",
       "2023-10-14 07:00:00                NaN                     NaN            NaN   \n",
       "2023-10-14 07:15:00                NaN                     NaN            NaN   \n",
       "2023-10-14 07:30:00                NaN                     NaN            NaN   \n",
       "2023-10-14 07:45:00                NaN                     NaN            NaN   \n",
       "2023-10-14 08:00:00                NaN                     NaN            NaN   \n",
       "\n",
       "station              Flow Sunderland Bridge  Flow Witton Park  \\\n",
       "dateTime                                                        \n",
       "1999-11-26 00:00:00                     NaN               NaN   \n",
       "1999-11-27 00:00:00                     NaN               NaN   \n",
       "1999-11-28 00:00:00                     NaN               NaN   \n",
       "1999-11-29 00:00:00                     NaN               NaN   \n",
       "1999-11-30 00:00:00                     NaN               NaN   \n",
       "...                                     ...               ...   \n",
       "2023-10-14 07:00:00                     NaN               NaN   \n",
       "2023-10-14 07:15:00                     NaN               NaN   \n",
       "2023-10-14 07:30:00                     NaN               NaN   \n",
       "2023-10-14 07:45:00                     NaN               NaN   \n",
       "2023-10-14 08:00:00                     NaN               NaN   \n",
       "\n",
       "station              Rainfall Copley  ...  Rainfall Copley -6d  \\\n",
       "dateTime                              ...                        \n",
       "1999-11-26 00:00:00              NaN  ...                  NaN   \n",
       "1999-11-27 00:00:00              NaN  ...             0.000000   \n",
       "1999-11-28 00:00:00              NaN  ...             0.399902   \n",
       "1999-11-29 00:00:00              NaN  ...             0.000000   \n",
       "1999-11-30 00:00:00              NaN  ...             0.000000   \n",
       "...                              ...  ...                  ...   \n",
       "2023-10-14 07:00:00              NaN  ...                  NaN   \n",
       "2023-10-14 07:15:00              NaN  ...                  NaN   \n",
       "2023-10-14 07:30:00              NaN  ...                  NaN   \n",
       "2023-10-14 07:45:00              NaN  ...                  NaN   \n",
       "2023-10-14 08:00:00              NaN  ...                  NaN   \n",
       "\n",
       "station              Rainfall Darlington Lingfield Way -6d  \\\n",
       "dateTime                                                     \n",
       "1999-11-26 00:00:00                                    NaN   \n",
       "1999-11-27 00:00:00                               0.000000   \n",
       "1999-11-28 00:00:00                               2.799316   \n",
       "1999-11-29 00:00:00                               0.000000   \n",
       "1999-11-30 00:00:00                               0.000000   \n",
       "...                                                    ...   \n",
       "2023-10-14 07:00:00                                    NaN   \n",
       "2023-10-14 07:15:00                                    NaN   \n",
       "2023-10-14 07:30:00                                    NaN   \n",
       "2023-10-14 07:45:00                                    NaN   \n",
       "2023-10-14 08:00:00                                    NaN   \n",
       "\n",
       "station              Rainfall Evenwood Gate -6d  \\\n",
       "dateTime                                          \n",
       "1999-11-26 00:00:00                         NaN   \n",
       "1999-11-27 00:00:00                    0.000000   \n",
       "1999-11-28 00:00:00                    3.599121   \n",
       "1999-11-29 00:00:00                    0.000000   \n",
       "1999-11-30 00:00:00                    0.000000   \n",
       "...                                         ...   \n",
       "2023-10-14 07:00:00                         NaN   \n",
       "2023-10-14 07:15:00                         NaN   \n",
       "2023-10-14 07:30:00                         NaN   \n",
       "2023-10-14 07:45:00                         NaN   \n",
       "2023-10-14 08:00:00                         NaN   \n",
       "\n",
       "station              Rainfall Harpington Hill Farm -6d  Rainfall Tunstall -6d  \\\n",
       "dateTime                                                                        \n",
       "1999-11-26 00:00:00                                NaN                    NaN   \n",
       "1999-11-27 00:00:00                           0.000000               0.000000   \n",
       "1999-11-28 00:00:00                           2.799316               4.600098   \n",
       "1999-11-29 00:00:00                           0.000000               0.000000   \n",
       "1999-11-30 00:00:00                           0.000000               0.000000   \n",
       "...                                                ...                    ...   \n",
       "2023-10-14 07:00:00                                NaN                    NaN   \n",
       "2023-10-14 07:15:00                                NaN                    NaN   \n",
       "2023-10-14 07:30:00                                NaN                    NaN   \n",
       "2023-10-14 07:45:00                                NaN                    NaN   \n",
       "2023-10-14 08:00:00                                NaN                    NaN   \n",
       "\n",
       "station              Rainfall Copley -7d  \\\n",
       "dateTime                                   \n",
       "1999-11-26 00:00:00             0.000000   \n",
       "1999-11-27 00:00:00             0.399902   \n",
       "1999-11-28 00:00:00             0.000000   \n",
       "1999-11-29 00:00:00             0.000000   \n",
       "1999-11-30 00:00:00             0.000000   \n",
       "...                                  ...   \n",
       "2023-10-14 07:00:00                  NaN   \n",
       "2023-10-14 07:15:00                  NaN   \n",
       "2023-10-14 07:30:00                  NaN   \n",
       "2023-10-14 07:45:00                  NaN   \n",
       "2023-10-14 08:00:00                  NaN   \n",
       "\n",
       "station              Rainfall Darlington Lingfield Way -7d  \\\n",
       "dateTime                                                     \n",
       "1999-11-26 00:00:00                               0.000000   \n",
       "1999-11-27 00:00:00                               2.799316   \n",
       "1999-11-28 00:00:00                               0.000000   \n",
       "1999-11-29 00:00:00                               0.000000   \n",
       "1999-11-30 00:00:00                               0.000000   \n",
       "...                                                    ...   \n",
       "2023-10-14 07:00:00                                    NaN   \n",
       "2023-10-14 07:15:00                                    NaN   \n",
       "2023-10-14 07:30:00                                    NaN   \n",
       "2023-10-14 07:45:00                                    NaN   \n",
       "2023-10-14 08:00:00                                    NaN   \n",
       "\n",
       "station              Rainfall Evenwood Gate -7d  \\\n",
       "dateTime                                          \n",
       "1999-11-26 00:00:00                    0.000000   \n",
       "1999-11-27 00:00:00                    3.599121   \n",
       "1999-11-28 00:00:00                    0.000000   \n",
       "1999-11-29 00:00:00                    0.000000   \n",
       "1999-11-30 00:00:00                    0.000000   \n",
       "...                                         ...   \n",
       "2023-10-14 07:00:00                         NaN   \n",
       "2023-10-14 07:15:00                         NaN   \n",
       "2023-10-14 07:30:00                         NaN   \n",
       "2023-10-14 07:45:00                         NaN   \n",
       "2023-10-14 08:00:00                         NaN   \n",
       "\n",
       "station              Rainfall Harpington Hill Farm -7d  Rainfall Tunstall -7d  \n",
       "dateTime                                                                       \n",
       "1999-11-26 00:00:00                           0.000000               0.000000  \n",
       "1999-11-27 00:00:00                           2.799316               4.600098  \n",
       "1999-11-28 00:00:00                           0.000000               0.000000  \n",
       "1999-11-29 00:00:00                           0.000000               0.000000  \n",
       "1999-11-30 00:00:00                           0.000000               0.000000  \n",
       "...                                                ...                    ...  \n",
       "2023-10-14 07:00:00                                NaN                    NaN  \n",
       "2023-10-14 07:15:00                                NaN                    NaN  \n",
       "2023-10-14 07:30:00                                NaN                    NaN  \n",
       "2023-10-14 07:45:00                                NaN                    NaN  \n",
       "2023-10-14 08:00:00                                NaN                    NaN  \n",
       "\n",
       "[475082 rows x 164 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\river-level\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "df_lagged.to_feather('data/river_wear_lagged.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('COMP2271_DS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e118ba02d0d63f0776027b45aa6c2794efdfedf6985533f6e5e4217ae01154a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
